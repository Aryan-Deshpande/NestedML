{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNN43w+glYASV0UeiG50k8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryan-Deshpande/NestedML/blob/master/1PytorchBestPractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKfY9iacaxC4",
        "outputId": "df06b963-4e11-47a5-e5c7-e28b6779ea4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for time\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch numpy time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Sequential Layers When Possible"
      ],
      "metadata": {
        "id": "TqDHpRB-bDBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ANN,self).__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(2,16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16,16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16,3)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "WIhclXW7a8cT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't Make Lists of Layers --> affects when tensor is on GPU, this is because List elements created are now untracked. \n",
        "Use Sequential as a work around."
      ],
      "metadata": {
        "id": "ZIDGYGJ8ci1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ANN,self).__init__()\n",
        "\n",
        "    self.midlayers =[]\n",
        "\n",
        "    self.firstlayer = nn.Linear(30,12)\n",
        "\n",
        "    for _ in range(230):\n",
        "      self.midlayers.append(nn.Linear(12,12))\n",
        "      self.midlayers.append(nn.ReLU())\n",
        "    \n",
        "    self.midlayers = nn.Sequential(*self.midlayers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.firstlayer(x)\n",
        "    out = self.midlayers(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "GeLesqvnchkb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Use of Distributions"
      ],
      "metadata": {
        "id": "eW7DfWItehj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANN()\n",
        "input_tensor = torch.rand(5,2)\n",
        "\n",
        "print(input_tensor)\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVOHpWwielVZ",
        "outputId": "9b6abfc8-b849-412a-a9bc-b588e653663b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0937, 0.5864],\n",
            "        [0.1742, 0.2689],\n",
            "        [0.1240, 0.3428],\n",
            "        [0.5674, 0.4190],\n",
            "        [0.7353, 0.0128]])\n",
            "tensor([[-0.0806, -0.1216, -0.2025],\n",
            "        [-0.0885, -0.1334, -0.2154],\n",
            "        [-0.0864, -0.1308, -0.2138],\n",
            "        [-0.0694, -0.1286, -0.2046],\n",
            "        [-0.0774, -0.1514, -0.2228]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical Distribution \n",
        "\n",
        "# in this case for example 3 classes, with probability\n",
        "\n",
        "from torch.distributions import Categorical\n",
        "dist = Categorical(logits=output)\n",
        "dist\n",
        "\n",
        "# get probabilty / alt to softmax\n",
        "dist.probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdQ-1s0hxU9",
        "outputId": "cead3261-867a-47b1-be6f-70c1175c465a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3515, 0.3374, 0.3111],\n",
              "        [0.3525, 0.3370, 0.3105],\n",
              "        [0.3525, 0.3372, 0.3103],\n",
              "        [0.3551, 0.3347, 0.3102],\n",
              "        [0.3580, 0.3325, 0.3095]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take Samples\n",
        "dist.sample()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76mSlEIfiYqI",
        "outputId": "43968b92-3f9e-4b76-81d1-66b0e31ec405"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batches = "
      ],
      "metadata": {
        "id": "sfVnfMBdjMeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [torch.rand(5,2) for _ in range(5)]\n",
        "print(batches)\n",
        "losses = []\n",
        "for batch in batches:\n",
        "# calc pred\n",
        "# calc loss\n",
        "  losses.append(loss.detatch()) # detatch value from gradient graph or use loss.item()\n",
        "# optimization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l__aOzr5jM3P",
        "outputId": "e3df76ca-d80b-41d6-f1ae-6ad5ea274e35"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0.6899, 0.4502],\n",
            "        [0.2887, 0.1596],\n",
            "        [0.5705, 0.3988],\n",
            "        [0.1335, 0.4364],\n",
            "        [0.1050, 0.7308]]), tensor([[0.9811, 0.9357],\n",
            "        [0.6772, 0.8858],\n",
            "        [0.6825, 0.6819],\n",
            "        [0.8916, 0.6004],\n",
            "        [0.9495, 0.6301]]), tensor([[0.9618, 0.9874],\n",
            "        [0.2279, 0.0791],\n",
            "        [0.2217, 0.4189],\n",
            "        [0.5168, 0.9927],\n",
            "        [0.2380, 0.6607]]), tensor([[0.9967, 0.0416],\n",
            "        [0.7096, 0.9539],\n",
            "        [0.0997, 0.3158],\n",
            "        [0.6946, 0.5875],\n",
            "        [0.7974, 0.0979]]), tensor([[0.0341, 0.2136],\n",
            "        [0.8287, 0.5938],\n",
            "        [0.6018, 0.0812],\n",
            "        [0.8676, 0.6472],\n",
            "        [0.5697, 0.7418]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean or Delete Model from GPU"
      ],
      "metadata": {
        "id": "d_4GyLKmlD51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc # garbage collection\n",
        "del_it = ANN()\n",
        "\n",
        "del del_it\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "gkPZVYf7lGpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ofcourse eval before testing !!!"
      ],
      "metadata": {
        "id": "cJT_R4cQkcKH"
      }
    }
  ]
}